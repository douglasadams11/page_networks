{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replication of `rank_output.ipynb`**\n",
    "\n",
    "**This notebook produces ranking of economic recovery pages based on the tfdf_max metric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the output of the random walks is a single set of pages. End users will prefer a ranked list of pages. This ranking should have a tendency to rank pages from the target WUJ higher than pages not in that WUJ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking by page frequency-random walk frequency\n",
    "\n",
    "#### An example\n",
    "\n",
    "The most successful random walk method has been to perform multiple random walks and combine the pages visited by each one into a single set of pages.\n",
    "\n",
    "Each random walk traverses a path of pages. Since we perform multiple random walks, we have multiple paths. Some pages will appear on more paths than others. Some pages will appear more frequently per path.\n",
    "\n",
    "For example: suppose you perform two random walks and each one traverses the following path:\n",
    "\n",
    "- [A, C, D, C, X, Y, Z] \n",
    "- [A, C, B, D, Q, P, M]\n",
    "\n",
    "Pages A, C and D are common to both paths. However, C occurs twice on the first path, which no other page does. Hence, C should be ranked first, followed by A and D in joint second. The remaining pages are equally ranked at the bottom.\n",
    "\n",
    "#### Page frequency-path frequency\n",
    "\n",
    "Inspired by the tf-idf (\"term frequency-inverse document frequency\") metric from NLP, we create the tf-df metric, \"term frequency-document frequency\". Translated into random walk parlance, this is \"page frequency-path frequency\". Where \"page frequency\" is the number of occurences of a given page on a given path taken by a random walk, and, \"path frequency\" is the number of random walk paths on which a given page occurs at least once.\n",
    "\n",
    "Mathematically,\n",
    "\n",
    "$pf(r,p)$ is the frequency of page $p$ on a single random walk $r$,\n",
    "\n",
    "$$\\text{pf}(r,p) = f_{r,p}$$\n",
    "\n",
    "Where $f_{r,p}$ is the count of a page on a random walk path.\n",
    "\n",
    "The path frequency is a measure of how common a given page is to all random walks performed, i.e. if it's common or rare across all random walks,\n",
    "\n",
    "$$\\text{rwf}(p,R) = |\\{r \\in R : p \\in r\\}|$$\n",
    "\n",
    "Where $R$ is the set of paths taken by all random walks and $|\\{r \\in R : p \\in r\\}|$ is the number of random walks on which the page $p$ occurs. For instance, in the above example, page C occurs on two random walk paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can compute the page frequency-path frequency metric. We start by constructing an $n\\times m$ matrix, $A$, where $n$ is the number of random walks performed and $m$ is the number of unique pages visited across all random walks.\n",
    "\n",
    "Hence, $A_{r,p}=f_{r,p}$, i.e. the value on the $p$-th column of the $r$-th row is the the number of occurrences of page $p$ on random walk $r$.\n",
    "\n",
    "Then, for each page, we compute the path frequency score $\\text{rwf}(p,R)$. Doing this for each page gives a vector of length $m$, called $v$, and we convert this into a diagonal matrix: $V=\\text{diag}(v)$, where the elements of $v$ occupy the main diagonal.\n",
    "\n",
    "Once we have this, we simply calculate $AV$. This means each $(AV)_{r,p}=f_{r,p} \\text{rwf}(p,R)$.\n",
    "\n",
    "There are multiple ways to proceed from here, but somehow we need to compress $AV$ down into a vector, where we have a score for each page. We could average each column, we could take the max, the min, and so on.\n",
    "\n",
    "In our implementation, each page is ranked by the maximum score for its column in $AV$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, a demo is shown of this ranking system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.randomwalks as rw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(4894)\n",
    "np.random.seed(846)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_to_remove = [\n",
    "    \"/\",\n",
    "    \"/search/all\",\n",
    "    \"/find-covid-19-lateral-flow-test-site\",\n",
    "    \"/guidance/coronavirus-covid-19-getting-tested\",\n",
    "    \"/register-coronavirus-antibody-test\",\n",
    "    \"/entering-staying-uk/foreign-nationals-working-in-uk\",\n",
    "    \"/business-finance-support/business-cash-advance-uk\",\n",
    "    \"/government/publications/applying-to-the-register-of-apprenticeship-training-providers-roatp\",\n",
    "    \"/guidance/esfa-business-operations-help-and-support\",\n",
    "    \"/business-finance-support/business-growth-calderdale\",\n",
    "    \"/business-finance-support/low-carbon-workspaces-buckinghamshire\",\n",
    "    \"/log-test-site-covid19-results\",\n",
    "    \"/guidance/apprenticeships-resources-for-teachers-and-advisers\",\n",
    "    \"/business-finance-support/south-east-creatives-seccads\",\n",
    "    \"/business-finance-support/construction-industry-training-board-citb-grants-scheme-england\",\n",
    "    \"/government/publications/turkey-list-of-lawyers/list-of-lawyers-in-ankara-and-gaziantep\",\n",
    "    \"/business-finance-support/agri-tech-cornwall-cornwall-and-the-isles-of-scilly\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# er_pages is a list of pages known to be within the economic recovery WUJ\n",
    "# this will be used to help evaluate the ranking system\n",
    "\n",
    "er_pages = pd.read_excel('../data/inputs/2021-11-12 - Economic recovery pages.xlsx', sheet_name='Top pages').pagePathv2.to_list()\n",
    "\n",
    "# get networkx graph\n",
    "G = nx.read_gpickle(\"../data/inputs/functional_session_hit_directed_graph_er.gpickle\").to_undirected()\n",
    "G.remove_nodes_from(pages_to_remove)\n",
    "# reformat the graph to make it compliant with existing random walk functions\n",
    "# i.e. add the path to a name property and set the index to be a number\n",
    "\n",
    "for index,data in G.nodes(data=True):\n",
    "    data['properties'] = dict()\n",
    "    data['properties']['name'] = index\n",
    "\n",
    "\n",
    "G = nx.convert_node_labels_to_integers(G, first_label=0, ordering='default', label_attribute=None)\n",
    "\n",
    "# get adjacency matrix of G\n",
    "A = nx.adj_matrix(G, weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seeds from where random walks will be initialised\n",
    "seeds = (\n",
    "    '/find-a-job',\n",
    "    '/universal-credit',\n",
    "    '/government/collections/financial-support-for-businesses-during-coronavirus-covid-19'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7a018033974d8fa532b83a89c9abe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = rw.repeat_random_walks(steps=100, repeats=100, T=A, G=G, seed_pages=seeds, proba=False, combine='union', level=1, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_scores = rw.page_freq_path_freq_ranking(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [path for paths in results['paths_taken'] for path in paths]\n",
    "\n",
    "\n",
    "pages_visited = {page: i for i, page in zip(range(len(results['pages_visited'])), results['pages_visited'])}\n",
    "\n",
    "tf = np.zeros((len(paths), len(pages_visited)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "page_scores['ER'] = page_scores.pagePath.isin(er_pages)\n",
    "colour = (page_scores.ER == True).map({True: 'background-color: black', False: ''})\n",
    "# Comment out so that later cells run ok\n",
    "# otherwise \"Styling\" causes errors\n",
    "# page_scores = page_scores.style.apply(lambda s: colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns to output\n",
    "\n",
    "Add additional information to csv output: \n",
    "- document type\n",
    "- document super type\n",
    "- number of sessions that visit this page\n",
    "- number of sessions where this page is an entrance hit\n",
    "- number of sessions where this page is an exit hit\n",
    "- number of sessions where this page is both an entrance and exit hit\n",
    "- how frequent the page occurs in the whole user journey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df with `pagePath`: `documentType`, `sessionHitsAll`, `entranceHit`, `exitHit`, `entranceAndExitHit`\n",
    "df_dict = {info['properties']['name']: [info['documentType'], info['sessionHitsAll'], info['entranceHit'], info['exitHit'], info['entranceAndExitHit']] for node, info in G.nodes(data=True)}\n",
    "df_dict = {k:v for (k,v) in df_dict.items() if k in page_scores['pagePath'].tolist()}\n",
    "df_info = pd.DataFrame.from_dict(df_dict, orient='index', columns=['documentType', 'sessionHitsAll', 'entranceHit', 'exitHit', 'entranceAndExitHit']).rename_axis('pagePath').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df with document supertypes\n",
    "news_and_comms_doctypes = {'medical_safety_alert', 'drug_safety_update', 'news_article', \n",
    "                           'news_story', 'press_release', 'world_location_news_article', \n",
    "                           'world_news_story', 'fatality_notice', 'fatality_notice', \n",
    "                           'tax_tribunal_decision', 'utaac_decision', 'asylum_support_decision', \n",
    "                           'employment_appeal_tribunal_decision', 'employment_tribunal_decision', \n",
    "                           'employment_tribunal_decision', 'service_standard_report', 'cma_case', \n",
    "                           'decision', 'oral_statement', 'written_statement', 'authored_article', \n",
    "                           'correspondence', 'speech', 'government_response', 'case_study' \n",
    "}\n",
    "\n",
    "service_doctypes = {'completed_transaction', 'local_transaction', 'form', 'calculator',\n",
    "                    'smart_answer', 'simple_smart_answer', 'place', 'licence', 'step_by_step_nav', \n",
    "                    'transaction', 'answer', 'guide'\n",
    "}\n",
    "\n",
    "guidance_and_reg_doctypes = {'regulation', 'detailed_guide', 'manual', 'manual_section',\n",
    "                             'guidance', 'map', 'calendar', 'statutory_guidance', 'notice',\n",
    "                             'international_treaty', 'travel_advice', 'promotional', \n",
    "                             'international_development_fund', 'countryside_stewardship_grant',\n",
    "                             'esi_fund', 'business_finance_support_scheme', 'statutory_instrument',\n",
    "                             'hmrc_manual', 'standard'\n",
    "}\n",
    "\n",
    "policy_and_engage_doctypes = {'impact_assessment', 'policy_paper', 'open_consultation',\n",
    "                              'policy_paper', 'closed_consultation', 'consultation_outcome',\n",
    "                              'policy_and_engagement'  \n",
    "}\n",
    "\n",
    "research_and_stats_doctypes = {'dfid_research_output', 'independent_report', 'research', \n",
    "                               'statistics', 'national_statistics', 'statistics_announcement',\n",
    "                               'national_statistics_announcement', 'official_statistics_announcement',\n",
    "                               'statistical_data_set', 'official_statistics'\n",
    "}\n",
    "\n",
    "transparency_doctypes = {'transparency', 'corporate_report', 'foi_release', 'aaib_report',\n",
    "                         'raib_report', 'maib_report'\n",
    "}\n",
    "\n",
    "document_type_dict = dict.fromkeys(list(set(df_info['documentType'])))\n",
    "\n",
    "for docType, docSupertype in document_type_dict.items():\n",
    "    if docType in news_and_comms_doctypes: \n",
    "        document_type_dict[docType] = 'news and communication'\n",
    "    \n",
    "    elif docType in service_doctypes:\n",
    "        document_type_dict[docType] = 'services'\n",
    "    \n",
    "    elif docType in guidance_and_reg_doctypes:\n",
    "        document_type_dict[docType] = 'guidance and regulation'\n",
    " \n",
    "    elif docType in policy_and_engage_doctypes:\n",
    "        document_type_dict[docType] = 'policy and engagement'\n",
    "    \n",
    "    elif docType in research_and_stats_doctypes:\n",
    "        document_type_dict[docType] = 'research and statistics'\n",
    "    \n",
    "    elif docType in transparency_doctypes:\n",
    "        document_type_dict[docType] = 'transparency'\n",
    "    \n",
    "    else: \n",
    "        document_type_dict[docType] = 'other' \n",
    "\n",
    "df_docSuper = pd.DataFrame(document_type_dict.items(), columns=['documentType', 'documentSupertype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs \n",
    "df_merged = pd.merge(page_scores, df_info, on='pagePath')\n",
    "df_merged = pd.merge(df_merged, df_docSuper, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagePath</th>\n",
       "      <th>tfdf_saliency</th>\n",
       "      <th>tfdf_max</th>\n",
       "      <th>tfdf_mean</th>\n",
       "      <th>ER</th>\n",
       "      <th>documentType</th>\n",
       "      <th>sessionHitsAll</th>\n",
       "      <th>entranceHit</th>\n",
       "      <th>exitHit</th>\n",
       "      <th>entranceAndExitHit</th>\n",
       "      <th>documentSupertype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/find-a-job</td>\n",
       "      <td>50625.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>168.750000</td>\n",
       "      <td>True</td>\n",
       "      <td>transaction</td>\n",
       "      <td>71667</td>\n",
       "      <td>18532</td>\n",
       "      <td>4157</td>\n",
       "      <td>44191</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/browse/working</td>\n",
       "      <td>29584.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>98.613333</td>\n",
       "      <td>False</td>\n",
       "      <td>mainstream_browse_page</td>\n",
       "      <td>15967</td>\n",
       "      <td>312</td>\n",
       "      <td>951</td>\n",
       "      <td>84</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/prove-right-to-work</td>\n",
       "      <td>23716.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>79.053333</td>\n",
       "      <td>False</td>\n",
       "      <td>transaction</td>\n",
       "      <td>68277</td>\n",
       "      <td>13171</td>\n",
       "      <td>8498</td>\n",
       "      <td>38338</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/universal-credit</td>\n",
       "      <td>21609.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>72.030000</td>\n",
       "      <td>True</td>\n",
       "      <td>guide</td>\n",
       "      <td>4140</td>\n",
       "      <td>217</td>\n",
       "      <td>1076</td>\n",
       "      <td>24</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/contact-jobcentre-plus</td>\n",
       "      <td>21025.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>70.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>guide</td>\n",
       "      <td>19282</td>\n",
       "      <td>2123</td>\n",
       "      <td>7788</td>\n",
       "      <td>5298</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/request-copy-criminal-record</td>\n",
       "      <td>18225.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>60.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>transaction</td>\n",
       "      <td>29136</td>\n",
       "      <td>6285</td>\n",
       "      <td>2940</td>\n",
       "      <td>16671</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/jobseekers-allowance</td>\n",
       "      <td>17689.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>58.963333</td>\n",
       "      <td>True</td>\n",
       "      <td>guide</td>\n",
       "      <td>16855</td>\n",
       "      <td>1102</td>\n",
       "      <td>7080</td>\n",
       "      <td>3136</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/apply-apprenticeship</td>\n",
       "      <td>17424.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>58.080000</td>\n",
       "      <td>True</td>\n",
       "      <td>answer</td>\n",
       "      <td>52112</td>\n",
       "      <td>11290</td>\n",
       "      <td>2323</td>\n",
       "      <td>36719</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/browse/benefits</td>\n",
       "      <td>15129.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>50.430000</td>\n",
       "      <td>False</td>\n",
       "      <td>mainstream_browse_page</td>\n",
       "      <td>4393</td>\n",
       "      <td>177</td>\n",
       "      <td>562</td>\n",
       "      <td>34</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/government/collections/financial-support-for-...</td>\n",
       "      <td>11449.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>38.163333</td>\n",
       "      <td>True</td>\n",
       "      <td>document_collection</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/brexit</td>\n",
       "      <td>11025.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>taxon</td>\n",
       "      <td>999</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/government/organisations/department-for-work-...</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>34.003333</td>\n",
       "      <td>False</td>\n",
       "      <td>organisation</td>\n",
       "      <td>4580</td>\n",
       "      <td>129</td>\n",
       "      <td>2677</td>\n",
       "      <td>261</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pagePath  tfdf_saliency  \\\n",
       "0                                         /find-a-job        50625.0   \n",
       "1                                     /browse/working        29584.0   \n",
       "2                                /prove-right-to-work        23716.0   \n",
       "3                                   /universal-credit        21609.0   \n",
       "4                             /contact-jobcentre-plus        21025.0   \n",
       "5                       /request-copy-criminal-record        18225.0   \n",
       "6                               /jobseekers-allowance        17689.0   \n",
       "7                               /apply-apprenticeship        17424.0   \n",
       "8                                    /browse/benefits        15129.0   \n",
       "9   /government/collections/financial-support-for-...        11449.0   \n",
       "10                                            /brexit        11025.0   \n",
       "11  /government/organisations/department-for-work-...        10201.0   \n",
       "\n",
       "    tfdf_max   tfdf_mean     ER            documentType  sessionHitsAll  \\\n",
       "0      225.0  168.750000   True             transaction           71667   \n",
       "1      172.0   98.613333  False  mainstream_browse_page           15967   \n",
       "2      154.0   79.053333  False             transaction           68277   \n",
       "3      147.0   72.030000   True                   guide            4140   \n",
       "4      145.0   70.083333  False                   guide           19282   \n",
       "5      135.0   60.750000  False             transaction           29136   \n",
       "6      133.0   58.963333   True                   guide           16855   \n",
       "7      132.0   58.080000   True                  answer           52112   \n",
       "8      123.0   50.430000  False  mainstream_browse_page            4393   \n",
       "9      107.0   38.163333   True     document_collection              27   \n",
       "10     105.0   36.750000  False                   taxon             999   \n",
       "11     101.0   34.003333  False            organisation            4580   \n",
       "\n",
       "    entranceHit  exitHit  entranceAndExitHit documentSupertype  \n",
       "0         18532     4157               44191          services  \n",
       "1           312      951                  84             other  \n",
       "2         13171     8498               38338          services  \n",
       "3           217     1076                  24          services  \n",
       "4          2123     7788                5298          services  \n",
       "5          6285     2940               16671          services  \n",
       "6          1102     7080                3136          services  \n",
       "7         11290     2323               36719          services  \n",
       "8           177      562                  34             other  \n",
       "9             4        6                   0             other  \n",
       "10           60       20                   1             other  \n",
       "11          129     2677                 261             other  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.iloc[:12, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reoder and rename df columns \n",
    "df_merged = df_merged[['pagePath', 'documentType', 'documentSupertype', 'sessionHitsAll', 'entranceHit', 'exitHit', 'entranceAndExitHit', 'tfdf_max']]\n",
    "# df_merged = df_merged.rename(columns={'pagePath': 'page path', 'documentType': 'document type', 'documentSupertype': 'document supertype', 'sessionHitsAll': 'number of sessions that visit this page', 'entranceHit': 'number of sessions where this page is an entrance hit', 'exitHit': 'number of sessions where this page is an exit hit', 'entranceAndExitHit': 'number of sessions where this page is both an entrance and exit hit', 'tfdf_max': 'how frequent the page occurs in the whole user journey'})\n",
    "# DO NOT RENAME THE TDX_MAX COLUMN\n",
    "df_merged = df_merged.rename(columns={'pagePath': 'page path', 'documentType': 'document type', 'documentSupertype': 'document supertype', 'sessionHitsAll': 'number of sessions that visit this page', 'entranceHit': 'number of sessions where this page is an entrance hit', 'exitHit': 'number of sessions where this page is an exit hit', 'entranceAndExitHit': 'number of sessions where this page is both an entrance and exit hit'})\n",
    "\n",
    "\n",
    "# save df\n",
    "df_merged.to_csv('../data/outputs/original_method/original_method_ranking', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8b846935c606cea246de54deed5846dcd1684508b0f7522a02f36eb958d20d0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
