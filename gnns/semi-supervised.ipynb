{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/inputs/NER2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape\n",
    "print('NER', df.shape[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating column name\n",
    "df.rename(columns = {'Unnamed: 0':'index'}, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values (pages with no relevant named entities) with zeroes\n",
    "df = df.fillna(0)\n",
    "# Replacing any anomolous entries with 0\n",
    "df = df.replace(r'^\\s*$', 0, regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have no duplicate nodes\n",
    "max(df[\"url\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the index\n",
    "df.set_index('index')\n",
    "df = df.drop(columns = ['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "x = df.to_numpy(dtype=np.compat.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing in the node classification labels \n",
    "df_labels = pd.read_csv(\"../data/inputs/pages_ranked_with_data_labelled.csv\")\n",
    "# df_labels = df_labels[[\"page path\", \"label\"]]\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to have labels for each node (economic recovery or not economic recovery)\n",
    "'''\n",
    "In the form:\n",
    "\n",
    "|| page_link   || relevant (y/n) ||\n",
    "|| ------------||----------------||\n",
    "|| page_link_0 ||        1       ||\n",
    "|| page_link_1 ||        0       ||\n",
    "|| page_link_2 ||        1       ||\n",
    "...\n",
    "'''\n",
    "# Make sure we have no duplicate nodes\n",
    "max(df_labels[\"url\"].value_counts())\n",
    "\n",
    "# Remove irrelevant columns\n",
    "df_labels = df_labels.drop(columns=[\"url\", \"index\"])\n",
    "\n",
    "df_labels.shape[0]\n",
    "\n",
    "# To numpy again... \n",
    "y = df_labels.to_numpy(dtype=np.compat.long)\n",
    "print(y.shape)\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train/val/test idx masks\n",
    "tm = pd.read_csv(\"../data/inputs/test_masks.csv\")\n",
    "tm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving masks into numpy\n",
    "train_mask = tm[0:100].to_numpy(dtype=np.compat.long)\n",
    "val_mask = tm[100:224].to_numpy(dtype=np.compat.long)\n",
    "test_mask = tm[224:].to_numpy(dtype=np.compat.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating the edge df\n",
    "df_edges = pd.read_csv(\"../edge_list.csv\")\n",
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Some pages were removed from the list prior to NER work\n",
    "due to the pae no longer existing or there being < 20 \n",
    "characters in the page's text field.\n",
    "\n",
    "It is now necessary to remove these nodes from the edge dataset,\n",
    "as this was attained from N2V approach.\n",
    "'''\n",
    "\n",
    "# Creating a list of pages to be removed\n",
    "pages_to_remove = [\n",
    "    \"/\",\n",
    "    \"/search/all\",\n",
    "    \"/find-covid-19-lateral-flow-test-site\",\n",
    "    \"/guidance/coronavirus-covid-19-getting-tested\",\n",
    "    \"/register-coronavirus-antibody-test\",\n",
    "    \"/entering-staying-uk/foreign-nationals-working-in-uk\",\n",
    "    \"/business-finance-support/business-cash-advance-uk\",\n",
    "    \"/government/publications/applying-to-the-register-of-apprenticeship-training-providers-roatp\",\n",
    "    \"/guidance/esfa-business-operations-help-and-support\",\n",
    "    \"/business-finance-support/business-growth-calderdale\",\n",
    "    \"/business-finance-support/low-carbon-workspaces-buckinghamshire\",\n",
    "    \"/log-test-site-covid19-results\",\n",
    "    \"/guidance/apprenticeships-resources-for-teachers-and-advisers\",\n",
    "    \"/business-finance-support/south-east-creatives-seccads\",\n",
    "    \"/business-finance-support/construction-industry-training-board-citb-grants-scheme-england\",\n",
    "    \"/government/publications/turkey-list-of-lawyers/list-of-lawyers-in-ankara-and-gaziantep\",\n",
    "    \"/business-finance-support/agri-tech-cornwall-cornwall-and-the-isles-of-scilly\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing pages from sources nodes\n",
    "df_edges_1 = df_edges[~df_edges[\"source\"].isin(pages_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing pages from target nodes\n",
    "df_edges_2 = df_edges_1[~df_edges_1[\"target\"].isin(pages_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing null rows\n",
    "df_edges_3 = df_edges_2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to extract the edges\n",
    "''' \n",
    "In the form:\n",
    "\n",
    "[[0, 0, 0, 0, 0 , 0 , 0 , ...],\n",
    " [1, 5, 7, 9, 11, 14, 16, ...]]\n",
    "\n",
    "Where this represents links existing between page 0 and 1, 5, 7, 9, 11, 14, 16...\n",
    "'''\n",
    "\n",
    "# gives df with edge weights (3 rows)\n",
    "# want to use this later when get all working\n",
    "# df_edges_3 = df_edges_3.drop(columns=[\"index\", \"source\", \"target\"])\n",
    "\n",
    "# gives df without edge weights (2 rows)\n",
    "df_edges_3 = df_edges_3.drop(columns=[\"index\", \"source\", \"target\", \"edgeWeight\"])\n",
    "\n",
    "\n",
    "df_edges_3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposing and changing type\n",
    "df_edges = df_edges_3.transpose()\n",
    "df_edges = df_edges.astype(np.compat.long)\n",
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To numpy again\n",
    "z = df_edges.to_numpy(dtype=np.compat.long)\n",
    "print(z.shape)\n",
    "print(z[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pytorch-geometric dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of classes\n",
    "# In this case 1 = relevant, 0 = not relevant\n",
    "# Therefore, 2 classes\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting np arrays to tensors\n",
    "x = torch.Tensor(x)\n",
    "y = torch.Tensor(y)\n",
    "edge_index = torch.Tensor(z)\n",
    "train_mask = torch.Tensor(train_mask)\n",
    "val_mask = torch.Tensor(val_mask)\n",
    "test_mask = torch.Tensor(test_mask)\n",
    "num_classes = torch.Tensor(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing tensor type from float to long\n",
    "x = x.type(torch.LongTensor)\n",
    "y = y.type(torch.LongTensor)\n",
    "edge_index = edge_index.type(torch.LongTensor)\n",
    "train_mask = train_mask.type(torch.LongTensor)\n",
    "val_mask = val_mask.type(torch.LongTensor)\n",
    "test_mask = test_mask.type(torch.LongTensor)\n",
    "num_classes = num_classes.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pytorch-geometric dataset\n",
    "dataset = Data(x = x, \n",
    "            edge_index=edge_index,\n",
    "            y=y,\n",
    "            train_mask=train_mask,\n",
    "            val_mask=val_mask,\n",
    "            test_mask=test_mask,\n",
    "            num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building out the GNN\n",
    "\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "\n",
    "# dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating GCN\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "feb72aa86adf3dbe491716fb35fe8b95aef07c373b2aed386ae31cecd3b83cf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
