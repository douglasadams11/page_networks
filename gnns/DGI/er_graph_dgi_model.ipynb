{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models import DGI, LogReg\n",
    "from utils import process\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# from src import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_pickle_file(file_name, dir_path=\"./data/outputs\"):\n",
    "    file_path = Path(dir_path + \"/\" + file_name)\n",
    "    f = open(file_path, 'rb')\n",
    "    file = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return (file)\n",
    "\n",
    "\n",
    "def dump_pickle_file(file, file_name, dir_path=\"./data/outputs\"):\n",
    "    # check directory exists (if not, create it)\n",
    "    isdir = os.path.isdir(dir_path)\n",
    "\n",
    "    if isdir == False:\n",
    "        os.mkdir(dir_path)\n",
    "        print(\"Directory created.\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    file_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "    f = open(file_path, 'wb')\n",
    "    pickle.dump(file, f)\n",
    "\n",
    "    return ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import src.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbryb\\AppData\\Local\\Temp\\ipykernel_10544\\2770947529.py:13: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  file = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "G2 = load_pickle_file(\"Graph_er\", dir_path=\"../../data/outputs\")\n",
    "A2 = load_pickle_file(\"Adjacency_er\", dir_path=\"../../data/outputs\")\n",
    "T2 = load_pickle_file(\"Transition_er\", dir_path=\"../../data/outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes of the graph 10631\n"
     ]
    }
   ],
   "source": [
    "nnodes = G2.number_of_nodes()\n",
    "print(\"Number of nodes of the graph\", G2.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.eye(nnodes, nnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbryb\\virual_envs_python\\pytorch_env\\lib\\site-packages\\torch_geometric\\datasets\\karate.py:32: DeprecationWarning: \n",
      "\n",
      "The scipy.sparse array containers will be used instead of matrices\n",
      "in Networkx 3.0. Use `to_scipy_sparse_array` instead.\n",
      "  adj = nx.to_scipy_sparse_matrix(G).tocoo()\n"
     ]
    }
   ],
   "source": [
    "# from torch_geometric.datasets import KarateClub\n",
    "\n",
    "# dataset = KarateClub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_karate = data.x\n",
    "type(features_karate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process features\n",
    "features_karate = csr_matrix(feature_matrix).tolil()\n",
    "features_karate, _ = process.preprocess_features(features_karate)\n",
    "features_karate = torch.FloatTensor(features_karate[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and proces grpah & adjacency matrix\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# G = nx.karate_club_graph()\n",
    "\n",
    "# A = nx.adjacency_matrix(G)\n",
    "\n",
    "A = process.normalize_adj(A2 + sp.eye(A2.shape[0]))\n",
    "\n",
    "\n",
    "sp_A = process.sparse_mx_to_torch_sparse_tensor(A)\n",
    "\n",
    "# features = torch.FloatTensor(features[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "batch_size = 1\n",
    "nb_epochs = 100\n",
    "patience = 10\n",
    "lr = 0.01\n",
    "l2_coef = 1e-5\n",
    "drop_prob = 0.0\n",
    "# specify size of encoding vector:\n",
    "hid_units = 50\n",
    "sparse = True\n",
    "nonlinearity = 'prelu' # special name to separate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Karate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_nodes = features_karate.shape[1]\n",
    "ft_size = features_karate.shape[2]\n",
    "# nb_classes = labels.shape[1]\n",
    "\n",
    "labels = [] # torch.FloatTensor(labels[np.newaxis])\n",
    "\n",
    "idx_train = np.arange(len(list(G2.nodes)))\n",
    "idx_val = np.arange(len(list(G2.nodes)))\n",
    "idx_test = np.arange(len(list(G2.nodes)))\n",
    "\n",
    "idx_train = torch.LongTensor(idx_train)\n",
    "idx_val = torch.LongTensor(idx_val)\n",
    "idx_test = torch.LongTensor(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.6931, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6925, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6888, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6826, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6757, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6668, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6592, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6509, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6423, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6379, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6280, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6169, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6078, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.6007, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.5915, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.5775, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.5635, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.5554, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.5400, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.5230, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.5135, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.4938, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.4736, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.4604, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.4464, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.4211, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.4008, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.3800, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.3629, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.3365, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.3182, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.3000, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.2859, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.2580, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.2419, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.2287, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.2099, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1947, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1815, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1700, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1518, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1453, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1373, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1267, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1181, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1111, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1037, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0997, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.1006, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0885, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0838, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0792, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0791, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0704, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0735, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0683, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0708, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0660, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0626, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0587, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0572, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0584, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0548, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0544, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0545, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0525, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0492, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0507, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0498, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0502, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0464, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0468, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0445, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0453, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0477, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0467, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0443, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0465, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0437, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0430, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0423, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0437, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0432, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0436, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0407, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0402, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0419, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0384, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0427, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0394, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0396, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0407, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0400, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0378, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0373, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0406, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0358, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0365, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loss: tensor(0.0382, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Loading 97th epoch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DGI(ft_size, hid_units, nonlinearity)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_coef)\n",
    "\n",
    "# b_xent applies logits follwoed by cross-entropy loss\n",
    "b_xent = nn.BCEWithLogitsLoss()\n",
    "# xent = nn.CrossEntropyLoss()\n",
    "\n",
    "# cnt_wait counts epochs from the last bes tmodel and implemnts early stopping\n",
    "cnt_wait = 0\n",
    "# initial best score for loss\n",
    "best = 1e9\n",
    "best_t = 0\n",
    "\n",
    "loss_history = list()\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    model.train()\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    idx = np.random.permutation(nb_nodes)\n",
    "    # reshuffle features\n",
    "    shuf_fts = features_karate[:, idx, :]\n",
    "    # vector of ones, length = number of nodes\n",
    "    lbl_1 = torch.ones(batch_size, nb_nodes)\n",
    "    # vector of zeros, length = number of nodes \n",
    "    lbl_2 = torch.zeros(batch_size, nb_nodes)\n",
    "    # length = 2*number of nodes, i.e. 5416\n",
    "    lbl = torch.cat((lbl_1, lbl_2), 1)\n",
    "\n",
    "    # the \"if\" affects onle \"sparse\" vs \"sp_adj\"\n",
    "    # i.e. mask = None, samp_bias1 = None, samp_bias2 = None\n",
    "    logits = model(features_karate, shuf_fts, sp_A if sparse else adj, sparse, None, None, None) \n",
    "\n",
    "    loss = b_xent(logits, lbl)\n",
    "    loss_history.append(loss.detach().numpy()) # use detach to get rid of the gradient\n",
    "\n",
    "    print('Loss:', loss)\n",
    "\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        best_t = epoch\n",
    "        cnt_wait = 0\n",
    "        torch.save(model.state_dict(), 'best_dgi.pkl')\n",
    "    else:\n",
    "        cnt_wait += 1\n",
    "\n",
    "    if cnt_wait == patience:\n",
    "        print('Early stopping!')\n",
    "        break\n",
    "\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "print('Loading {}th epoch'.format(best_t))\n",
    "model.load_state_dict(torch.load('best_dgi.pkl'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21262])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h contains node representations\n",
    "# s contains the overall metric representation\n",
    "h, s = model.embed(features_karate, sp_A, msk = None, sparse = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10631, 50])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23de9ff7520>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking of webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cosine_similarity_matrix(X, y):\n",
    "    '''\n",
    "    X is a matatrix of embeddings, with nodes in rows (i.e number of rows = number of nodes, \n",
    "    number of columns = number of latent dimensions).\n",
    "    '''\n",
    "    cosine_similarity = np.dot(X, y)/(np.linalg.norm(X, axis = 1)* np.linalg.norm(y))\n",
    "    \n",
    "    return( cosine_similarity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_l2_distance(embeddings, reference_vectors_embeddings):\n",
    "#     '''\n",
    "#     For given embeddings, and embeddings of reterence vectors, calulate mean and median distances\n",
    "#     from each embedding vector to reference vector embeddings.\n",
    "#     '''\n",
    "#     mean_distances = [np.linalg.norm(x - reference_vectors_embeddings, axis = 1).mean() for x in embeddings]\n",
    "#     median_distances = [np.median( np.linalg.norm(x - reference_vectors_embeddings, axis = 1) ) for x in embeddings]\n",
    "\n",
    "#     return(mean_distances, median_distances)\n",
    "\n",
    "# def calculate_cosine_distance(G, embeddings, seeds, stats = np.max):\n",
    "#     '''\n",
    "#     For any given node in G, calculate similairty to each seed page and return the given summary \n",
    "#     statistics of these scores.\n",
    "#     Returns scores for all nodes in G.\n",
    "#     '''\n",
    "\n",
    "#     rankings = list()\n",
    "#     page_paths = list()\n",
    "\n",
    "#     for node in G.nodes:\n",
    "\n",
    "#         rankings_node = list()\n",
    "\n",
    "#         for seed in seeds:\n",
    "#             rankings_node.append( calc_cosine_similarity(node, seed) )\n",
    "\n",
    "#         rankings.append( stats( rankings_node ) )\n",
    "#         page_paths.append( node )\n",
    "\n",
    "#     return( rankings, page_paths )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed_page_index(G, seed_page):\n",
    "    seed_node_index = np.where(np.array(a) == seed_page)[0]\n",
    "    seed_node_index = seed_node_index.astype(int)[0]\n",
    "\n",
    "    print( \"Seed node:\", list(G2.nodes)[seed_node_index] )\n",
    "    \n",
    "    return(seed_node_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rankings_dict(G, embeddings, seeds, metric = \"cosine\"):\n",
    "    \n",
    "    rankings = dict()\n",
    "\n",
    "    rankings[\"pages\"] = list(G.nodes)\n",
    "\n",
    "    for seed_page in seeds:\n",
    "\n",
    "        seed_node_index = get_seed_page_index(G, seed_page)\n",
    "        seed_node_embedding = embeddings[seed_node_index]\n",
    "        \n",
    "        if metric == \"cosine\":\n",
    "            node_similarities = calc_cosine_similarity_matrix(embeddings, seed_node_embedding)\n",
    "        else:\n",
    "            node_similarities = np.linalg.norm(embeddings - seed_node_embedding)\n",
    "\n",
    "        rankings[seed_page] = node_similarities\n",
    "\n",
    "\n",
    "    return(rankings)\n",
    "\n",
    "\n",
    "def get_rankings_df(G, embeddings, seeds, metric = \"cosine\"):\n",
    "\n",
    "    emb_dict = get_rankings_dict(G, embeddings, seeds, metric= metric)\n",
    "        \n",
    "    emb_df = pd.DataFrame.from_dict(emb_dict)\n",
    "    \n",
    "    emb_df.set_index(\"pages\", inplace = True)\n",
    "    seed_cols = emb_df.columns\n",
    "    \n",
    "    emb_df[\"max\"]= emb_df[seed_cols].max(axis = 1)\n",
    "    emb_df[\"median\"] = emb_df[seed_cols].median(axis = 1)\n",
    "    emb_df[\"mean\"] = emb_df[seed_cols].mean(axis = 1)\n",
    "    emb_df[\"min\"]= emb_df[seed_cols].min(axis = 1)\n",
    "    \n",
    "    return(emb_df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data_1 = pd.read_csv('../../data/labelled/pages_ranked_with_data_labelled.csv')\n",
    "labelled_data_1 = labelled_data_1.loc[:,[\"page path\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE SAME FUNCTION AND IN N2V\n",
    "def calc_median_difference_n2v(df, labelled_data, standardise = True, page_path = \"pagePath\"):\n",
    "    '''df needs to be a result of calling rw.page_freq_path_freq_ranking()\n",
    "    \n",
    "    df needs to be ranked from top page to the worst page (i.e. index represents ranking).'''\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    df_labels = df.merge(labelled_data_1, left_on = page_path, right_on = \"page path\")\n",
    "    df_labels.reset_index(inplace = True, drop = False)\n",
    "    df_labels.rename(columns = {\"index\": \"rank\"}, inplace = True)\n",
    "\n",
    "    med_ranking_label1 = df_labels[df_labels[\"label\"] == 1][\"rank\"].median()\n",
    "    med_ranking_label0 = df_labels[df_labels[\"label\"] == 0][\"rank\"].median()\n",
    "    \n",
    "    if standardise == True:\n",
    "        score = (med_ranking_label0 - med_ranking_label1) / ( df_labels[df_labels[\"label\"] == 1][\"rank\"].std() +\n",
    "                                                            df_labels[df_labels[\"label\"] == 0][\"rank\"].std())\n",
    "    else:\n",
    "        score = med_ranking_label0 - med_ranking_label1\n",
    "    \n",
    "    return( score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_pages_used = [    \n",
    "    '/find-a-job',\n",
    "    '/universal-credit',\n",
    "    '/government/collections/financial-support-for-businesses-during-coronavirus-covid-19']\n",
    "\n",
    "\n",
    "seed_embeddings = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed node: /find-a-job\n",
      "Seed node: /universal-credit\n",
      "Seed node: /government/collections/financial-support-for-businesses-during-coronavirus-covid-19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>/find-a-job</th>\n",
       "      <th>/universal-credit</th>\n",
       "      <th>/government/collections/financial-support-for-businesses-during-coronavirus-covid-19</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/universal-credit</td>\n",
       "      <td>0.703397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772366</td>\n",
       "      <td>0.825254</td>\n",
       "      <td>0.703397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/find-a-job</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703397</td>\n",
       "      <td>0.471634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703397</td>\n",
       "      <td>0.725011</td>\n",
       "      <td>0.471634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/government/collections/financial-support-for-...</td>\n",
       "      <td>0.471634</td>\n",
       "      <td>0.772366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772366</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.471634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/sign-in-universal-credit</td>\n",
       "      <td>0.701284</td>\n",
       "      <td>0.972882</td>\n",
       "      <td>0.782108</td>\n",
       "      <td>0.972882</td>\n",
       "      <td>0.782108</td>\n",
       "      <td>0.818758</td>\n",
       "      <td>0.701284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/benefits-calculators</td>\n",
       "      <td>0.653661</td>\n",
       "      <td>0.968781</td>\n",
       "      <td>0.802347</td>\n",
       "      <td>0.968781</td>\n",
       "      <td>0.802347</td>\n",
       "      <td>0.808263</td>\n",
       "      <td>0.653661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pages  /find-a-job  \\\n",
       "0                                  /universal-credit     0.703397   \n",
       "1                                        /find-a-job     1.000000   \n",
       "2  /government/collections/financial-support-for-...     0.471634   \n",
       "3                          /sign-in-universal-credit     0.701284   \n",
       "4                              /benefits-calculators     0.653661   \n",
       "\n",
       "   /universal-credit  \\\n",
       "0           1.000000   \n",
       "1           0.703397   \n",
       "2           0.772366   \n",
       "3           0.972882   \n",
       "4           0.968781   \n",
       "\n",
       "   /government/collections/financial-support-for-businesses-during-coronavirus-covid-19  \\\n",
       "0                                           0.772366                                      \n",
       "1                                           0.471634                                      \n",
       "2                                           1.000000                                      \n",
       "3                                           0.782108                                      \n",
       "4                                           0.802347                                      \n",
       "\n",
       "        max    median      mean       min  \n",
       "0  1.000000  0.772366  0.825254  0.703397  \n",
       "1  1.000000  0.703397  0.725011  0.471634  \n",
       "2  1.000000  0.772366  0.748000  0.471634  \n",
       "3  0.972882  0.782108  0.818758  0.701284  \n",
       "4  0.968781  0.802347  0.808263  0.653661  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rankings_cosine = get_rankings_df(G2, embeddings, seed_pages_used, metric = \"cosine\")\n",
    "df_rankings_cosine = df_rankings_cosine.sort_values(by = \"max\", ascending = False).reset_index(drop = False)\n",
    "df_rankings_cosine.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed node: /find-a-job\n",
      "Seed node: /universal-credit\n",
      "Seed node: /government/collections/financial-support-for-businesses-during-coronavirus-covid-19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>/find-a-job</th>\n",
       "      <th>/universal-credit</th>\n",
       "      <th>/government/collections/financial-support-for-businesses-during-coronavirus-covid-19</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>21.762175</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>40.786503</td>\n",
       "      <td>21.762175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/guidance/immigration-rules/immigration-rules-...</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>21.762175</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>40.786503</td>\n",
       "      <td>21.762175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/guidance/data-analyst</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>21.762175</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>40.786503</td>\n",
       "      <td>21.762175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/overseas-domestic-worker-visa/domestic-worker...</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>21.762175</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>40.786503</td>\n",
       "      <td>21.762175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/plug-in-car-van-grants</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>21.762175</td>\n",
       "      <td>50.524151</td>\n",
       "      <td>50.073181</td>\n",
       "      <td>40.786503</td>\n",
       "      <td>21.762175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pages  /find-a-job  \\\n",
       "0                                                  /    50.524151   \n",
       "1  /guidance/immigration-rules/immigration-rules-...    50.524151   \n",
       "2                             /guidance/data-analyst    50.524151   \n",
       "3  /overseas-domestic-worker-visa/domestic-worker...    50.524151   \n",
       "4                            /plug-in-car-van-grants    50.524151   \n",
       "\n",
       "   /universal-credit  \\\n",
       "0          50.073181   \n",
       "1          50.073181   \n",
       "2          50.073181   \n",
       "3          50.073181   \n",
       "4          50.073181   \n",
       "\n",
       "   /government/collections/financial-support-for-businesses-during-coronavirus-covid-19  \\\n",
       "0                                          21.762175                                      \n",
       "1                                          21.762175                                      \n",
       "2                                          21.762175                                      \n",
       "3                                          21.762175                                      \n",
       "4                                          21.762175                                      \n",
       "\n",
       "         max     median       mean        min  \n",
       "0  50.524151  50.073181  40.786503  21.762175  \n",
       "1  50.524151  50.073181  40.786503  21.762175  \n",
       "2  50.524151  50.073181  40.786503  21.762175  \n",
       "3  50.524151  50.073181  40.786503  21.762175  \n",
       "4  50.524151  50.073181  40.786503  21.762175  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rankings_l2 = get_rankings_df(G2, embeddings, seed_pages_used, metric = \"l2\")\n",
    "df_rankings_l2 = df_rankings_l2.sort_values(by = \"min\", ascending = True).reset_index(drop = False)\n",
    "df_rankings_l2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1654604753910266"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_median_difference_n2v(df_rankings_cosine, labelled_data_1, \n",
    "                           standardise = True, page_path = \"pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01604114333438033"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_median_difference_n2v(df_rankings_l2, labelled_data_1, \n",
    "                           standardise = True, page_path = \"pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
