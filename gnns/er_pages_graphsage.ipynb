{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "\n",
    "\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph import StellarDiGraph\n",
    "\n",
    "import warnings \n",
    "import collections\n",
    "from stellargraph import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stellargraph as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbryb\\AppData\\Local\\Temp\\ipykernel_5356\\4158135398.py:13: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  file = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_pickle_file(file_name, dir_path=\"./data/outputs\"):\n",
    "    file_path = Path(dir_path + \"/\" + file_name)\n",
    "    f = open(file_path, 'rb')\n",
    "    file = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return (file)\n",
    "\n",
    "\n",
    "G2 = load_pickle_file(\"Graph_er\", dir_path=\"../data/outputs\")\n",
    "A2 = load_pickle_file(\"Adjacency_er\", dir_path=\"../data/outputs\")\n",
    "T2 = load_pickle_file(\"Transition_er\", dir_path=\"../data/outputs\")\n",
    "\n",
    "\n",
    "G = load_pickle_file(\"Graph_er_weighted_wfeatures\", dir_path=\"../data/outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_feature': array([1., 0., 0., ..., 0., 0., 0.])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes['/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sg = StellarDiGraph.from_networkx(G, node_features = \"node_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24342119512247948]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_sg._edge_weights('/','/search/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07841605329166496]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_sg._edge_weights('/search/all', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_number = 10\n",
    "walk_length = 5\n",
    "\n",
    "walker = BiasedRandomWalk(\n",
    "    G_sg,\n",
    "    n=walk_number,\n",
    "    length=walk_length,\n",
    "    p=10,  # defines probability, 1/p, of returning to source node\n",
    "    q=10,  # defines probability, 1/q, for moving to a node away from the source node\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_samples = UnsupervisedSampler(G_sg, nodes=list(G_sg.nodes()), walker=walker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "from stellargraph.layer import GraphSAGE, link_classification\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 4\n",
    "num_samples = [10, 5]\n",
    "\n",
    "generator = GraphSAGELinkGenerator(G_sg, batch_size, num_samples)\n",
    "train_gen = generator.flow(unsupervised_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [50, 50]\n",
    "graphsage = GraphSAGE(\n",
    "    layer_sizes=layer_sizes, generator=generator, bias=True, dropout=0.0, normalize=\"l2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and expose input and output sockets of graphsage, for node pair inputs:\n",
    "x_inp, x_out = graphsage.in_out_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'ip' method to combine node embeddings into edge embeddings\n"
     ]
    }
   ],
   "source": [
    "prediction = link_classification(\n",
    "    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    ")(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbryb\\virual_envs_python\\pytorch_env\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=[keras.metrics.binary_accuracy],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "17010/17010 [==============================] - 5593s 328ms/step - loss: 0.6890 - binary_accuracy: 0.5520\n",
      "Epoch 2/4\n",
      "17010/17010 [==============================] - 5548s 326ms/step - loss: 0.6870 - binary_accuracy: 0.5578\n",
      "Epoch 3/4\n",
      "17010/17010 [==============================] - 5536s 325ms/step - loss: 0.6865 - binary_accuracy: 0.5581\n",
      "Epoch 4/4\n",
      "17010/17010 [==============================] - 5532s 325ms/step - loss: 0.6864 - binary_accuracy: 0.5577\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=False,\n",
    "    workers=4,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         The UnsupervisedSampler is responsible for sampling walks in the given graph\n",
    "#         and returning positive and negative samples w.r.t. those walks, on demand.\n",
    "\n",
    "#         The positive samples are all the (target, context) pairs from the walks and the negative\n",
    "#         samples are contexts generated for each target based on a sampling distribution.\n",
    "\n",
    "#         By default, a UniformRandomWalk is used, but a custom `walker` can be specified instead. An\n",
    "#         error will be raised if other parameters are specified along with a custom `walker`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import GraphSAGENodeGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sg.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method flow in module stellargraph.mapper.sampled_node_generators:\n",
      "\n",
      "flow(node_ids, targets=None, shuffle=False, seed=None) method of stellargraph.mapper.sampled_node_generators.GraphSAGENodeGenerator instance\n",
      "    Creates a generator/sequence object for training or evaluation\n",
      "    with the supplied node ids and numeric targets.\n",
      "    \n",
      "    The node IDs are the nodes to train or inference on: the embeddings\n",
      "    calculated for these nodes are passed to the downstream task. These\n",
      "    are a subset of the nodes in the graph.\n",
      "    \n",
      "    The targets are an array of numeric targets corresponding to the\n",
      "    supplied node_ids to be used by the downstream task. They should\n",
      "    be given in the same order as the list of node IDs.\n",
      "    If they are not specified (for example, for use in prediction),\n",
      "    the targets will not be available to the downstream task.\n",
      "    \n",
      "    Note that the shuffle argument should be True for training and\n",
      "    False for prediction.\n",
      "    \n",
      "    Args:\n",
      "        node_ids: an iterable of node IDs\n",
      "        targets: a 2D array of numeric targets with shape\n",
      "            ``(len(node_ids), target_size)``\n",
      "        shuffle (bool): If True the node_ids will be shuffled at each\n",
      "            epoch, if False the node_ids will be processed in order.\n",
      "    \n",
      "    Returns:\n",
      "        A NodeSequence object to use with with StellarGraph models\n",
      "        in Keras methods ``fit``, ``evaluate``,\n",
      "        and ``predict``\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GraphSAGENodeGenerator(G_sg, batch_size, num_samples).flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp_src = x_inp[0::2]\n",
    "x_out_src = x_out[0]\n",
    "embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_ids = node_subjects.index\n",
    "node_gen = GraphSAGENodeGenerator(G_sg, batch_size, num_samples).flow(G_sg.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stellargraph.mapper.sequences.NodeSequence at 0x22b6d130550>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 43s 188ms/step\n"
     ]
    }
   ],
   "source": [
    "node_embeddings = embedding_model.predict(node_gen, workers=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10631, 50)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cosine_similarity_matrix(X, y):\n",
    "    '''\n",
    "    X is a matatrix of embeddings, with nodes in rows (i.e number of rows = number of nodes, \n",
    "    number of columns = number of latent dimensions).\n",
    "    '''\n",
    "    cosine_similarity = np.dot(X, y)/(np.linalg.norm(X, axis = 1)* np.linalg.norm(y))\n",
    "    \n",
    "    return( cosine_similarity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed_page_index(G, seed_page):\n",
    "    seed_node_index = np.where(np.array(G.nodes) == seed_page)[0]\n",
    "    seed_node_index = seed_node_index.astype(int)[0]\n",
    "\n",
    "    print( \"Seed node:\", list(G2.nodes)[seed_node_index] )\n",
    "    \n",
    "    return(seed_node_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rankings_dict(G, embeddings, seeds, metric = \"cosine\"):\n",
    "    \n",
    "    rankings = dict()\n",
    "\n",
    "    rankings[\"pages\"] = list(G.nodes)\n",
    "\n",
    "    for seed_page in seeds:\n",
    "\n",
    "        seed_node_index = get_seed_page_index(G, seed_page)\n",
    "        seed_node_embedding = embeddings[seed_node_index]\n",
    "        \n",
    "        if metric == \"cosine\":\n",
    "            node_similarities = calc_cosine_similarity_matrix(embeddings, seed_node_embedding)\n",
    "        else:\n",
    "            node_similarities = np.linalg.norm(embeddings - seed_node_embedding)\n",
    "\n",
    "        rankings[seed_page] = node_similarities\n",
    "\n",
    "\n",
    "    return(rankings)\n",
    "\n",
    "\n",
    "def get_rankings_df(G, embeddings, seeds, metric = \"cosine\"):\n",
    "\n",
    "    emb_dict = get_rankings_dict(G, embeddings, seeds, metric= metric)\n",
    "        \n",
    "    emb_df = pd.DataFrame.from_dict(emb_dict)\n",
    "    \n",
    "    emb_df.set_index(\"pages\", inplace = True)\n",
    "    seed_cols = emb_df.columns\n",
    "    \n",
    "    emb_df[\"max\"]= emb_df[seed_cols].max(axis = 1)\n",
    "    emb_df[\"median\"] = emb_df[seed_cols].median(axis = 1)\n",
    "    emb_df[\"mean\"] = emb_df[seed_cols].mean(axis = 1)\n",
    "    emb_df[\"min\"]= emb_df[seed_cols].min(axis = 1)\n",
    "    \n",
    "    return(emb_df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data_1 = pd.read_csv('../data/labelled/pages_ranked_with_data_labelled.csv')\n",
    "labelled_data_1 = labelled_data_1.loc[:,[\"page path\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE SAME FUNCTION AND IN N2V\n",
    "def calc_median_difference_n2v(df, labelled_data, standardise = True, page_path = \"pagePath\"):\n",
    "    '''df needs to be a result of calling rw.page_freq_path_freq_ranking()\n",
    "    \n",
    "    df needs to be ranked from top page to the worst page (i.e. index represents ranking).'''\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    df_labels = df.merge(labelled_data_1, left_on = page_path, right_on = \"page path\")\n",
    "    df_labels.reset_index(inplace = True, drop = False)\n",
    "    df_labels.rename(columns = {\"index\": \"rank\"}, inplace = True)\n",
    "\n",
    "    med_ranking_label1 = df_labels[df_labels[\"label\"] == 1][\"rank\"].median()\n",
    "    med_ranking_label0 = df_labels[df_labels[\"label\"] == 0][\"rank\"].median()\n",
    "    \n",
    "    if standardise == True:\n",
    "        score = (med_ranking_label0 - med_ranking_label1) / ( df_labels[df_labels[\"label\"] == 1][\"rank\"].std() +\n",
    "                                                            df_labels[df_labels[\"label\"] == 0][\"rank\"].std())\n",
    "    else:\n",
    "        score = med_ranking_label0 - med_ranking_label1\n",
    "    \n",
    "    return( score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_pages_used = [    \n",
    "    '/find-a-job',\n",
    "    '/universal-credit',\n",
    "    '/government/collections/financial-support-for-businesses-during-coronavirus-covid-19']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed node: /find-a-job\n",
      "Seed node: /universal-credit\n",
      "Seed node: /government/collections/financial-support-for-businesses-during-coronavirus-covid-19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>/find-a-job</th>\n",
       "      <th>/universal-credit</th>\n",
       "      <th>/government/collections/financial-support-for-businesses-during-coronavirus-covid-19</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/government/collections/financial-support-for-...</td>\n",
       "      <td>0.083953</td>\n",
       "      <td>-0.048485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083953</td>\n",
       "      <td>0.345156</td>\n",
       "      <td>-0.048485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/find-a-job</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401406</td>\n",
       "      <td>0.083953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401406</td>\n",
       "      <td>0.495120</td>\n",
       "      <td>0.083953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/universal-credit</td>\n",
       "      <td>0.401406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401406</td>\n",
       "      <td>0.450974</td>\n",
       "      <td>-0.048485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/get-state-pension</td>\n",
       "      <td>0.770952</td>\n",
       "      <td>0.371240</td>\n",
       "      <td>-0.068289</td>\n",
       "      <td>0.770952</td>\n",
       "      <td>0.371240</td>\n",
       "      <td>0.357968</td>\n",
       "      <td>-0.068289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/guidance/if-we-refuse-your-application-for-an...</td>\n",
       "      <td>0.744767</td>\n",
       "      <td>0.456866</td>\n",
       "      <td>0.133820</td>\n",
       "      <td>0.744767</td>\n",
       "      <td>0.456866</td>\n",
       "      <td>0.445151</td>\n",
       "      <td>0.133820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pages  /find-a-job  \\\n",
       "0  /government/collections/financial-support-for-...     0.083953   \n",
       "1                                        /find-a-job     1.000000   \n",
       "2                                  /universal-credit     0.401406   \n",
       "3                                 /get-state-pension     0.770952   \n",
       "4  /guidance/if-we-refuse-your-application-for-an...     0.744767   \n",
       "\n",
       "   /universal-credit  \\\n",
       "0          -0.048485   \n",
       "1           0.401406   \n",
       "2           1.000000   \n",
       "3           0.371240   \n",
       "4           0.456866   \n",
       "\n",
       "   /government/collections/financial-support-for-businesses-during-coronavirus-covid-19  \\\n",
       "0                                           1.000000                                      \n",
       "1                                           0.083953                                      \n",
       "2                                          -0.048485                                      \n",
       "3                                          -0.068289                                      \n",
       "4                                           0.133820                                      \n",
       "\n",
       "        max    median      mean       min  \n",
       "0  1.000000  0.083953  0.345156 -0.048485  \n",
       "1  1.000000  0.401406  0.495120  0.083953  \n",
       "2  1.000000  0.401406  0.450974 -0.048485  \n",
       "3  0.770952  0.371240  0.357968 -0.068289  \n",
       "4  0.744767  0.456866  0.445151  0.133820  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rankings_cosine = get_rankings_df(G2, node_embeddings, seed_pages_used, metric = \"cosine\")\n",
    "df_rankings_cosine = df_rankings_cosine.sort_values(by = \"max\", ascending = False).reset_index(drop = False)\n",
    "df_rankings_cosine.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed node: /find-a-job\n",
      "Seed node: /universal-credit\n",
      "Seed node: /government/collections/financial-support-for-businesses-during-coronavirus-covid-19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>/find-a-job</th>\n",
       "      <th>/universal-credit</th>\n",
       "      <th>/government/collections/financial-support-for-businesses-during-coronavirus-covid-19</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/</td>\n",
       "      <td>132.021332</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>135.669296</td>\n",
       "      <td>132.021332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/guidance/immigration-rules/immigration-rules-...</td>\n",
       "      <td>132.021332</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>135.669296</td>\n",
       "      <td>132.021332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/guidance/data-analyst</td>\n",
       "      <td>132.021332</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>135.669296</td>\n",
       "      <td>132.021332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/overseas-domestic-worker-visa/domestic-worker...</td>\n",
       "      <td>132.021332</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>135.669296</td>\n",
       "      <td>132.021332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/plug-in-car-van-grants</td>\n",
       "      <td>132.021332</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>135.375595</td>\n",
       "      <td>135.669296</td>\n",
       "      <td>132.021332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pages  /find-a-job  \\\n",
       "0                                                  /   132.021332   \n",
       "1  /guidance/immigration-rules/immigration-rules-...   132.021332   \n",
       "2                             /guidance/data-analyst   132.021332   \n",
       "3  /overseas-domestic-worker-visa/domestic-worker...   132.021332   \n",
       "4                            /plug-in-car-van-grants   132.021332   \n",
       "\n",
       "   /universal-credit  \\\n",
       "0         135.375595   \n",
       "1         135.375595   \n",
       "2         135.375595   \n",
       "3         135.375595   \n",
       "4         135.375595   \n",
       "\n",
       "   /government/collections/financial-support-for-businesses-during-coronavirus-covid-19  \\\n",
       "0                                         139.610992                                      \n",
       "1                                         139.610992                                      \n",
       "2                                         139.610992                                      \n",
       "3                                         139.610992                                      \n",
       "4                                         139.610992                                      \n",
       "\n",
       "          max      median        mean         min  \n",
       "0  139.610992  135.375595  135.669296  132.021332  \n",
       "1  139.610992  135.375595  135.669296  132.021332  \n",
       "2  139.610992  135.375595  135.669296  132.021332  \n",
       "3  139.610992  135.375595  135.669296  132.021332  \n",
       "4  139.610992  135.375595  135.669296  132.021332  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rankings_l2 = get_rankings_df(G2, node_embeddings, seed_pages_used, metric = \"l2\")\n",
    "df_rankings_l2 = df_rankings_l2.sort_values(by = \"min\", ascending = True).reset_index(drop = False)\n",
    "df_rankings_l2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15228365706759867"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_median_difference_n2v(df_rankings_cosine, labelled_data_1, \n",
    "                           standardise = True, page_path = \"pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01604114333438033"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_median_difference_n2v(df_rankings_l2, labelled_data_1, \n",
    "                           standardise = True, page_path = \"pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://stellargraph.readthedocs.io/en/stable/demos/embeddings/graphsage-unsupervised-sampler-embeddings.html\n",
    "\n",
    "Node embeddings are learnt by solving a simple classification task:\n",
    "given a large set of “positive” `(target, context)` node pairs generated from random walks performed on the graph (i.e., node pairs that co-occur within a certain context window in random walks), and an equally large set of “negative” node pairs that are randomly selected from the graph according to a certain distribution, learn a binary classifier that predicts whether arbitrary node pairs are likely to co-occur in a random walk performed on the graph. \n",
    "\n",
    "Through learning this simple binary node-pair-classification task, the model automatically learns an inductive mapping from attributes of nodes and their neighbors to node embeddings in a high-dimensional vector space, which preserves structural and feature similarities of the nodes. \n",
    "\n",
    "Unlike embeddings obtained by algorithms such as Node2Vec, this mapping is inductive: given a new node (with attributes) and its links to other nodes in the graph (which was unseen during model training), we can evaluate its embeddings without having to re-train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture**\n",
    "\n",
    "The architecture of the node pair classifier is the following. Input node pairs (with node features) are fed, together with the graph structure, into a pair of identical GraphSAGE encoders, producing a pair of node embeddings. These embeddings are then fed into a node pair classification layer, which applies a binary operator to those node embeddings (e.g., concatenating them), and passes the resulting node pair embeddings through a linear transform followed by a binary activation (e.g., sigmoid), thus predicting a binary label for the node pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifications**\n",
    "\n",
    "The Unsupervised GraphSAGE requires a training sample that can be either provided as a list of (target, context) node pairs or it can be provided with an UnsupervisedSampler instance that takes care of generating positive and negative samples of node pairs on demand. In this demo we discuss the latter technique.\n",
    "\n",
    "\n",
    "The UnsupervisedSampler class takes in a Stellargraph graph instance. The generator method in the UnsupervisedSampler is responsible for generating equal number of positive and negative node pair samples from the graph for training. The samples are generated by performing uniform random walks over the graph, using UniformRandomWalk object. Positive (target, context) node pairs are extracted from the walks, and for each positive pair a corresponding negative pair (target, node) is generated by randomly sampling node from the degree distribution of the graph. Once the batch_size number of samples is accumulated, the generator yields a list of positive and negative node pairs along with their respective 1/0 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_samples = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the node pair generator for sampling and streaming the training data to the model. The node pair generator essentially “maps” pairs of nodes (target, context) to the input of GraphSAGE: it either takes minibatches of node pairs, or an UnsupervisedSampler instance which generates the minibatches of node pairs on demand. The generator samples 2-hop subgraphs with (target, context) head nodes extracted from those pairs, and feeds them, together with the corresponding binary labels indicating which pair represent positive or negative sample, to the input layer of the node pair classifier with GraphSAGE node encoder, for SGD updates of the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final node pair classification layer that takes a pair of nodes’ embeddings produced by graphsage encoder, applies a binary operator to them to produce the corresponding node pair embedding (ip for inner product; other options for the binary operator can be seen by running a cell with ?link_classification in it), and passes it through a dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = link_classification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
